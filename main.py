import tkinter as tk
from tkinter import ttk, messagebox
from tkinter import simpledialog # API í‚¤ë¥¼ ë¬¼ì–´ë³¼ íŒì—…ì°½
import cv2
from PIL import Image, ImageTk
import threading
import time
import speech_recognition as sr
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker # [ìˆ˜ì •] ê·¸ë˜í”„ ì •ìˆ˜ ëˆˆê¸ˆìš©
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import random
import os
import json
import re
import pyaudio
import wave
import audioop

try:
    import app_config # ì„¤ì • íŒŒì¼ (app_config.py)
    from question_generator import DynamicQuestionGenerator, IMRADValidator
    from analysis_manager import AnalysisManager
    from ai_rewriter import AI_Announcer 
except ImportError as e:
    print(f"ê²½ê³ : í•„ìš”í•œ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("app_config.py, question_generator.py, analysis_manager.py, ai_rewriter.py íŒŒì¼ì´ main.pyì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    # ì„ì‹œ ëŒ€ì²´ (ì˜¤ë¥˜ ë°©ì§€ìš©)
    class DynamicQuestionGenerator: 
        def __init__(self, *args): pass # [ìˆ˜ì •] text_model ì¸ìˆ˜ ë°›ë„ë¡
    class IMRADValidator: 
        def __init__(self, *args): pass # [ìˆ˜ì •] text_model ì¸ìˆ˜ ë°›ë„ë¡
    class AnalysisManager: 
        def __init__(self, *args): pass
    class AI_Announcer: 
        def __init__(self, *args): pass
# --- ---

# --- ì „ì—­ ë³€ìˆ˜ (ì‹¤ì‹œê°„ ìŠ¤ë ˆë“œ ì œì–´ìš©) ---
is_recording = False
start_time = 0
speech_data = {"full_transcript": "", "word_count": 0, "filler_count": 0}
gaze_data = {"total_frames": 0, "looking_frames": 0}
audio_data = {"volumes": [], "tremble_count": 0}
timeline_markers = []
cap = None
out = None
recognizer = sr.Recognizer()
microphone = sr.Microphone()
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
pa = pyaudio.PyAudio() # .wav ì €ì¥ì„ ìœ„í•´ pa ì¸ìŠ¤í„´ìŠ¤ëŠ” ìœ ì§€

class App(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("AI Presentation Pro (Gemini Full Version)")
        self.geometry("1200x950")
        
        # app_config ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸ í›„ í°íŠ¸ ì„¤ì •
        if 'app_config' in globals() and hasattr(app_config, 'set_korean_font'):
            app_config.set_korean_font() 
        
        self.user_settings = {}
        self.original_script = ""
        self.style = ttk.Style()
        self.style.theme_use('clam')
        
        self.load_and_initialize_apis() # Gemini API ë¡œë“œ
        
        # ëª¨ë“ˆì´ ì •ìƒ ë¡œë“œë˜ì—ˆì„ ë•Œë§Œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        if 'app_config' in globals() and hasattr(app_config, 'STOPWORDS'):
            self.analysis_manager = AnalysisManager(app_config.STOPWORDS, app_config.COACHING_CONFIG)
            self.dynamic_generator = DynamicQuestionGenerator(self.text_model) 
            self.imrad_validator = IMRADValidator(self.text_model)
            self.ai_announcer = AI_Announcer(self.text_model) 
        else:
            # ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¹„ìƒìš© ì¸ìŠ¤í„´ìŠ¤ (ì˜¤ë¥˜ ë°©ì§€)
            self.analysis_manager = AnalysisManager({}, {})
            self.dynamic_generator = DynamicQuestionGenerator(None)
            self.imrad_validator = IMRADValidator(None)
            self.ai_announcer = AI_Announcer(None)

        self.extracted_keywords = []

        self.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.load_history()
        self.show_setup_page()

    def load_and_initialize_apis(self):
        """[ìˆ˜ì •] Gemini API í‚¤ë¡œ í…ìŠ¤íŠ¸ ëª¨ë¸ë§Œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. (TTS ëª¨ë¸ ì´ˆê¸°í™” ì‚­ì œ)"""
        
        # app_config ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if 'app_config' not in globals() or not hasattr(app_config, 'load_api_keys'):
            messagebox.showerror("ì¹˜ëª…ì  ì˜¤ë¥˜", "app_config ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.AI_AVAILABLE = False
            self.text_model = None
            return

        gemini_key = app_config.load_api_keys()
        
        if not gemini_key:
            gemini_key = simpledialog.askstring("Gemini API í‚¤ í•„ìš”", 
                                                "Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ëª¨ë“  AI ê¸°ëŠ¥ì— ì‚¬ìš©):\n", 
                                                parent=self)
            if gemini_key:
                app_config.save_api_keys(gemini_key) # Gemini í‚¤ë§Œ ì €ì¥

        self.text_model = None  # (MODIFIED) í…ìŠ¤íŠ¸ ëª¨ë¸
        self.AI_AVAILABLE = False

        if gemini_key:
            try:
                # [ìˆ˜ì •] app_config ëª¨ë“ˆì— ìˆëŠ” genai ì‚¬ìš©
                if 'app_config' in globals() and hasattr(app_config, 'genai'):
                    app_config.genai.configure(api_key=gemini_key)
                    
                    # (FIXED) 1. í…ìŠ¤íŠ¸ ëª¨ë¸ (gemini-2.5-pro)
                    self.text_model = app_config.genai.GenerativeModel('gemini-2.5-pro')
                    
                    self.AI_AVAILABLE = True
                    
                    print("Gemini APIê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (Text: gemini-2.5-pro)")
                else:
                    raise ImportError("app_config ëª¨ë“ˆì—ì„œ genaië¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            except Exception as e:
                print(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}")
                messagebox.showerror("API ì˜¤ë¥˜", f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n{e}")
        else:
            print("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")


    def on_closing(self):
        global is_recording, cap, out, pa
        is_recording = False
        if cap and cap.isOpened(): cap.release()
        if out: out.release()
        if pa: pa.terminate() 
        try:
            if os.path.exists("rewritten_script_output.wav"):
                os.remove("rewritten_script_output.wav")
            if os.path.exists("output.avi"):
                os.remove("output.avi")
            if os.path.exists("output.wav"):
                os.remove("output.wav")
                
        except: pass
        self.destroy()
        os._exit(0) # ìŠ¤ë ˆë“œê°€ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê°•ì œ ì¢…ë£Œ

    def load_history(self):
        self.history = []
        if 'app_config' in globals() and hasattr(app_config, 'HISTORY_FILE') and os.path.exists(app_config.HISTORY_FILE):
            try:
                with open(app_config.HISTORY_FILE, "r", encoding='utf-8') as f:
                    self.history = json.load(f)
            except: self.history = []

    def save_history(self, score):
        if 'app_config' not in globals() or not hasattr(app_config, 'HISTORY_FILE'): return
        self.history.append(score)
        #utf-8 ì¸ì½”ë”© ì¶”ê°€ (í•œê¸€ ê¹¨ì§ ë°©ì§€)
        with open(app_config.HISTORY_FILE, "w", encoding='utf-8') as f:
            json.dump(self.history, f, ensure_ascii=False, indent=4)

    def clear_window(self):
        self.unbind_all("<MouseWheel>")
        for widget in self.winfo_children(): widget.destroy()

    def show_setup_page(self):
        self.clear_window()
        frame = ttk.Frame(self)
        frame.pack(expand=True)
        ttk.Label(frame, text="ğŸ¤ AI Presentation Pro", font=("Arial", 30, "bold")).pack(pady=30)
        
        ttk.Label(frame, text="ë°œí‘œ ìœ í˜• ì„ íƒ:", font=("Arial", 14)).pack()
        self.atmosphere_var = tk.StringVar(value="ğŸ“˜ ì •ë³´ ì „ë‹¬í˜• (ì •í™•ì„± ì¤‘ì‹œ)")
        modes = ["ğŸ“˜ ì •ë³´ ì „ë‹¬í˜• (ì •í™•ì„± ì¤‘ì‹œ)", "ğŸ”¥ ì„¤ë“/ë™ê¸°ë¶€ì—¬í˜• (ì—ë„ˆì§€ ì¤‘ì‹œ)", "ğŸ¤ ê³µê°/ì†Œí†µí˜• (ë°¸ëŸ°ìŠ¤ ì¤‘ì‹œ)"]
        ttk.Combobox(frame, textvariable=self.atmosphere_var, values=modes, state="readonly", font=("Arial", 12), width=35).pack(pady=15)
        
        ttk.Button(frame, text="ì—°ìŠµ ì‹œì‘í•˜ê¸°", command=self.go_to_practice).pack(pady=20, ipadx=20, ipady=10)
        ttk.Button(frame, text="ğŸ“¢ AI ëŒ€ë³¸ ì¬ì‘ì„± (Gemini)", command=self.show_rewriter_window).pack(pady=10, ipadx=10, ipady=5)

    def go_to_practice(self):
        """ì—°ìŠµ í˜ì´ì§€ë¡œ ì´ë™"""
        self.user_settings['atmosphere'] = self.atmosphere_var.get()
        self.show_practice_page()

    def show_practice_page(self):
        self.clear_window()
        main_frame = ttk.Frame(self)
        main_frame.pack(fill='both', expand=True, padx=20, pady=20)
        top_frame = ttk.Frame(main_frame)
        top_frame.pack(pady=10)
        self.video_panel = ttk.Label(top_frame)
        self.video_panel.pack()
        self.audience_frame = tk.Frame(main_frame, bg="#e9ecef", bd=2, relief="sunken")
        self.audience_frame.pack(fill="x", padx=100, pady=10)
        self.aud_labels = [ttk.Label(self.audience_frame) for _ in range(2)]
        for lbl in self.aud_labels: lbl.pack(side="left", expand=True, padx=10, pady=10)
        self.update_audience_images('default', 'default') # [ìˆ˜ì •] ì²­ì¤‘ ì´ë¯¸ì§€ ë¡œë“œ
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(pady=20)
        self.btn_start = ttk.Button(control_frame, text="â–¶ ë…¹í™” ì‹œì‘", command=self.start_recording)
        self.btn_start.pack(side="left", padx=10)
        self.btn_question = ttk.Button(control_frame, text="âš¡ï¸ ëŒë°œ ì§ˆë¬¸", command=self.trigger_question_event, state="disabled")
        self.btn_question.pack(side="left", padx=10)
        self.btn_stop = ttk.Button(control_frame, text="â–  ê²°ê³¼ ë³´ê¸°", command=self.stop_recording, state="disabled")
        self.btn_stop.pack(side="left", padx=10)
        self.status_label = ttk.Label(main_frame, text="ì¤€ë¹„ ì™„ë£Œ", font=("Arial", 14), foreground="gray")
        self.status_label.pack()
        ttk.Label(main_frame, text="ğŸ“„ ë°œí‘œ ëŒ€ë³¸ (ë¶„ì„ì„ ìœ„í•´ í•„ìˆ˜ ì…ë ¥):", font=("Arial", 12)).pack(anchor='w')
        self.script_text = tk.Text(main_frame, height=6, font=("Arial", 11))
        self.script_text.pack(fill='x', pady=(5, 0))
        self.start_camera()

    def start_camera(self):
        global cap
        try:
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                messagebox.showerror("ì¹´ë©”ë¼ ì˜¤ë¥˜", "ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì´ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                self.show_setup_page()
                return
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640); cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.update_video_stream()
        except Exception as e:
            messagebox.showerror("ì¹´ë©”ë¼ ì˜¤ë¥˜", f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.show_setup_page()


    def update_video_stream(self):
        global gaze_data, cap
        if not self.winfo_exists(): return
        
        try:
            # [ìˆ˜ì •] capì´ Noneì´ê±°ë‚˜ ë‹«í˜”ìœ¼ë©´ ë£¨í”„ ì¤‘ë‹¨
            if cap is None or not cap.isOpened():
                print("ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨ë¨ (ìº¡ì²˜ ë¦´ë¦¬ì¦ˆë¨).")
                return 

            ret, frame = cap.read()
            if ret:
                if is_recording:
                    if out: out.write(frame) # out ê°ì²´ê°€ ì¡´ì¬í•  ë•Œë§Œ write
                    gaze_data['total_frames'] += 1
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
                    looking = False
                    for (x, y, w, h) in faces:
                        if 640 * 0.3 < (x + w // 2) < 640 * 0.7: looking = True
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0) if looking else (0, 0, 255), 2)
                    if looking: gaze_data['looking_frames'] += 1
                
                frame = cv2.flip(frame, 1)
                if is_recording: cv2.circle(frame, (30, 30), 10, (0, 0, 255), -1)
                
                # [ìˆ˜ì •] 640x360 (16:9 ë¹„ìœ¨)ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                img = ImageTk.PhotoImage(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((640, 360))) 
                self.video_panel.configure(image=img); self.video_panel.image = img
            
            # ë£¨í”„ ì§€ì†
            if self.winfo_exists():
                self.after(30, self.update_video_stream)
                
        except Exception as e:
            # ë¹„ë””ì˜¤ íŒ¨ë„ì´ íŒŒê´´ëœ í›„ì—ë„ self.afterê°€ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ ë°©ì§€
            if self.winfo_exists():
                print(f"ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
                self.after(1000, self.update_video_stream) # ì˜¤ë¥˜ ì‹œ 1ì´ˆ í›„ ì¬ì‹œë„

    def update_audience_images(self, s1, s2):
        """ì‹¤ì œ ì²­ì¤‘ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
          
            i1 = ImageTk.PhotoImage(Image.open(f"audience1_{s1}.png").resize((200, 150)))
            self.aud_labels[0].configure(image=i1); self.aud_labels[0].image = i1
            i2 = ImageTk.PhotoImage(Image.open(f"audience2_{s2}.png").resize((200, 150)))
            self.aud_labels[1].configure(image=i2); self.aud_labels[1].image = i2
        except Exception as e:
            # print(f"ì²­ì¤‘ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}") # ë””ë²„ê¹… ì‹œ ì£¼ì„ í•´ì œ
            pass # íŒŒì¼ì´ ì—†ì–´ë„ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì§€ ì•Šë„ë¡ pass

    def start_recording(self):
        global is_recording, start_time, out, speech_data, timeline_markers, gaze_data, audio_data, microphone
        if len(self.script_text.get("1.0", tk.END).strip()) < 10:
            messagebox.showwarning("ê²½ê³ ", "ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ëŒ€ë³¸ì„ 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        try:
            # [ìˆ˜ì •] ì „ì—­ microphone ê°ì²´ ì‚¬ìš©
            with microphone as source:
                print("ë§ˆì´í¬ ì¥ì¹˜ í™•ì¸ ì™„ë£Œ.")
        except Exception as e:
            messagebox.showerror("ì˜¤ë””ì˜¤ ì˜¤ë¥˜", f"ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n{e}")
            return

        is_recording = True; start_time = time.time()
        speech_data = {"full_transcript": "", "word_count": 0, "filler_count": 0}
        gaze_data = {"total_frames": 0, "looking_frames": 0}
        audio_data = {"volumes": [], "tremble_count": 0}
        timeline_markers = []
        self.raw_audio_frames = [] # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í†µí•© ì €ì¥ì„ ìœ„í•´ ì´ˆê¸°í™”
        
        try:
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))
        except Exception as e:
            messagebox.showerror("ë¹„ë””ì˜¤ ì“°ê¸° ì˜¤ë¥˜", f"ë¹„ë””ì˜¤ íŒŒì¼(output.avi)ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n{e}")
            is_recording = False
            return
            
        # ì˜¤ë””ì˜¤/STT í†µí•© ìŠ¤ë ˆë“œ ì‹œì‘
        threading.Thread(target=self.speech_recognition_thread, daemon=True).start()
        
        self.btn_start['state'] = 'disabled'; self.btn_stop['state'] = 'normal'; self.btn_question['state'] = 'normal'
        self.script_text['state'] = 'disabled'
        self.status_label.config(text="ğŸ”´ ë…¹í™” ë° ë¶„ì„ ì¤‘...", foreground="red")
        self.audience_loop() # [ìˆ˜ì •] ì²­ì¤‘ ë°˜ì‘ ë£¨í”„ ì‹œì‘

    def speech_recognition_thread(self):
        """[ìŠ¤ë ˆë“œ] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í†µí•© ê´€ë¦¬ (STT, WAV ì €ì¥, RMS ë¶„ì„)"""
        global speech_data, audio_data, recognizer, microphone
        last_vol = 0
        
        with microphone as source:
            # [ìˆ˜ì •] ìë™ ì„ê³„ê°’ ì„¤ì • (ë§ˆì´í¬ ë¯¼ê°ë„ í–¥ìƒ)
            print("ì£¼ë³€ ì†ŒìŒ ê°ì§€ ì¤‘... (1ì´ˆ)")
            recognizer.adjust_for_ambient_noise(source, duration=1)
            print(f"ë§ˆì´í¬ ì„ê³„ê°’ ìë™ ì„¤ì • ì™„ë£Œ: {recognizer.energy_threshold}")
            
            last_speech_end = time.time()
            
            while is_recording:
                try:
                    audio = recognizer.listen(source, timeout=2, phrase_time_limit=5)
                    
                    # 1. WAV ë…¹ìŒìš© ë°ì´í„° ì €ì¥
                    raw_data = audio.get_raw_data(convert_rate=microphone.SAMPLE_RATE, convert_width=microphone.SAMPLE_WIDTH)
                    self.raw_audio_frames.append(raw_data) # 'self' ì‚¬ìš©

                    # 2. ì—ë„ˆì§€/ë–¨ë¦¼ ë¶„ì„ìš© RMS ê³„ì‚°
                    rms = audioop.rms(raw_data, microphone.SAMPLE_WIDTH) 
                    if abs(rms - last_vol) > 2000 and rms > 500: 
                        audio_data['tremble_count'] += 1
                    last_vol = rms
                    audio_data['volumes'].append(rms)

                    # 3. STTìš© í…ìŠ¤íŠ¸ ë³€í™˜
                    text = recognizer.recognize_google(audio, language='ko-KR')
                    
                    # --- STT ì„±ê³µ í›„ ë°ì´í„° ì²˜ë¦¬ ---
                    timestamp = time.time() - start_time - 1.5
                    words = text.split() # 'words' ì •ì˜
                    speech_data['word_count'] += len(words)
                    speech_data['full_transcript'] += text + " "
                    segment_duration = time.time() - last_speech_end
                    last_speech_end = time.time()
                    
                    if segment_duration > 0.5:
                        instant_wpm = (len(words) / segment_duration) * 60
                        if instant_wpm > 220: self.add_marker(timestamp, 'âš¡ï¸') # 'self' ì‚¬ìš©
                        elif instant_wpm < 60 and len(words) > 2: self.add_marker(timestamp, 'ğŸ¢') # 'self' ì‚¬ìš©
                        
                    chunk_filler = 0
                    if 'app_config' in globals() and hasattr(app_config, 'FILLER_WORDS'):
                        for word in words: # 'word' ì •ì˜ ë° ì‚¬ìš©
                            if any(f in word for f in app_config.FILLER_WORDS):
                                chunk_filler += 1; speech_data['filler_count'] += 1
                    if chunk_filler > 0: self.add_marker(timestamp, 'ğŸ’¬') # 'self' ì‚¬ìš©
                    
                except sr.WaitTimeoutError: # ì¹¨ë¬µ
                    if time.time() - last_speech_end > 5.0:
                        self.add_marker(time.time() - start_time - 5.0, 'ğŸ¤') # 'self' ì‚¬ìš©
                        last_speech_end = time.time()
                    continue
                except sr.UnknownValueError: # STT ì¸ì‹ ì‹¤íŒ¨
                    print("STT: ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    pass 
                except Exception as e:
                    print(f"STT ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
                    time.sleep(0.5) 

    def add_marker(self, t, emoji):
        if not timeline_markers or (t - timeline_markers[-1]['time'] > 1.5) or timeline_markers[-1]['label'] != emoji:
            timeline_markers.append({'time': max(0.1, t), 'label': emoji})

    def audience_loop(self):
        """4ì´ˆë§ˆë‹¤ ì²­ì¤‘ í‘œì •ì„ ëœë¤í•˜ê²Œ ë³€ê²½í•©ë‹ˆë‹¤."""
        if not is_recording: return
        
        # 10% í™•ë¥ ë¡œ ë”´ì§“, 20% í™•ë¥ ë¡œ ì§‘ì¤‘, 70% í™•ë¥ ë¡œ ê¸°ë³¸
        s1 = random.choice(['default']*7 + ['focused']*2 + ['distracted'])
        s2 = random.choice(['default']*7 + ['focused']*2 + ['distracted'])
        self.update_audience_images(s1, s2)
        
        if self.winfo_exists(): self.after(4000, self.audience_loop) # 4ì´ˆë§ˆë‹¤ ë°˜ë³µ

    # =========================================================================
    # === [ìˆ˜ì •] "ì‘ë‹µ ì—†ìŒ" ë°©ì§€ë¥¼ ìœ„í•´ ëŒë°œ ì§ˆë¬¸ ë¡œì§ì„ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬ ===
    # =========================================================================
    def trigger_question_event(self):
        """AI í˜¸ì¶œì„ ë³„ë„ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬í•˜ì—¬ GUI ë©ˆì¶¤(ì‘ë‹µ ì—†ìŒ) ë°©ì§€"""
        if not self.winfo_exists(): return
        
        # 1. (ë©”ì¸ ìŠ¤ë ˆë“œ) GUI ì¦‰ì‹œ ë³€ê²½
        asker_idx = random.randint(0, 1)
        if asker_idx == 0: self.update_audience_images('question', 'focused')
        else: self.update_audience_images('focused', 'question')
        self.update() # UI ì¦‰ì‹œ ìƒˆë¡œê³ ì¹¨

        # 2. (ë©”ì¸ ìŠ¤ë ˆë“œ) AI ìŠ¤ë ˆë“œì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìˆ˜ì§‘
        try:
            script = self.script_text.get("1.0", tk.END).strip()
            mode = self.user_settings.get('atmosphere', 'ì •ë³´')
        except Exception as e:
            print(f"ëŒ€ë³¸ ì½ê¸° ì˜¤ë¥˜: {e}")
            return

        # 3. (ë©”ì¸ ìŠ¤ë ˆë“œ) AI ë° ê·œì¹™ ë¶„ì„ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        threading.Thread(target=self._trigger_question_thread, 
                         args=(script, mode), 
                         daemon=True).start()

    def _trigger_question_thread(self, script, mode):
        """(ì‘ì—… ìŠ¤ë ˆë“œ) AI ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„± (ì‹œê°„ ì†Œìš”)"""
        
        ai_question = None
        possible_questions = []
        
        # 1. (í•„ìˆ˜) ë°±ì—… ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ í™•ë³´
        if 'app_config' in globals() and hasattr(app_config, 'BACKUP_QUESTIONS'):
            possible_questions.extend(app_config.BACKUP_QUESTIONS)
        else:
            possible_questions.append("ë°œí‘œ ë‚´ìš© ì¤‘ì— ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ì ì€ ë¬´ì—‡ì¸ê°€ìš”?")

        # 2. (ì„ íƒ) AI/ê·œì¹™ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± (ëŠë¦° ì‘ì—…)
        if self.AI_AVAILABLE:
            try:
                if 'ì •ë³´' in mode:
                    ai_question = self.imrad_validator.generate_imrad_question(script)
                elif 'ì„¤ë“' in mode:
                    ai_question = self.dynamic_generator.generate_question(script, 'B')
                elif 'ê³µê°' in mode:
                    ai_question = self.dynamic_generator.generate_question(script, 'C')
                
                if ai_question:
                    possible_questions.append(ai_question)
                else:
                    print("AI/ê·œì¹™ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±ê¸°ê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"AI ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë°±ì—… ì§ˆë¬¸ë§Œ ì‚¬ìš©): {e}")

        # 3. ìµœì¢… ì§ˆë¬¸ ì„ íƒ
        final_question = random.choice(possible_questions)
        
        # 4. (ì‘ì—… ìŠ¤ë ˆë“œ) GUI ì—…ë°ì´íŠ¸(íŒì—…)ë¥¼ ë‹¤ì‹œ ë©”ì¸ ìŠ¤ë ˆë“œì— ìš”ì²­
        if self.winfo_exists():
            self.after(0, self._show_question_popup, final_question)

    def _show_question_popup(self, final_question):
        """(ë©”ì¸ ìŠ¤ë ˆë“œ) ì‘ì—… ìŠ¤ë ˆë“œê°€ ìš”ì²­í•œ íŒì—…ì°½ì„ ì•ˆì „í•˜ê²Œ í‘œì‹œ"""
        if not self.winfo_exists(): return
        
        self.add_marker(time.time() - start_time, 'â“')
        messagebox.showinfo("ğŸ’¡ ëŒë°œ ì§ˆë¬¸", final_question)
    # =========================================================================

    # =========================================================================
    # === [ìˆ˜ì •] "ì‘ë‹µ ì—†ìŒ" ë°©ì§€ë¥¼ ìœ„í•´ ë…¹í™” ì¤‘ë‹¨ ë¡œì§ì„ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬ ===
    # =========================================================================
    def stop_recording(self):
        """GUI ë©ˆì¶¤(ì‘ë‹µ ì—†ìŒ) ë°©ì§€ë¥¼ ìœ„í•´ AI ë¶„ì„ì„ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬"""
        global is_recording
        
        # 1. (ë©”ì¸ ìŠ¤ë ˆë“œ) ì¦‰ì‹œ ë…¹í™” ì¤‘ì§€
        is_recording = False
        
        # 2. (ë©”ì¸ ìŠ¤ë ˆë“œ) GUI ì¦‰ì‹œ ì—…ë°ì´íŠ¸
        self.original_script = self.script_text.get("1.0", tk.END).strip()
        self.btn_stop['state'] = 'disabled'
        self.btn_question['state'] = 'disabled'
        self.status_label.config(text="â³ ë…¹í™” ì¢…ë£Œ! ê²°ê³¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...", foreground="blue")
        self.update()
        
        # 3. (ë©”ì¸ ìŠ¤ë ˆë“œ) ëŠë¦° ì‘ì—…(íŒŒì¼ ì €ì¥, AI ë¶„ì„)ì„ ë³„ë„ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
        threading.Thread(target=self._finalize_and_analyze_thread, daemon=True).start()

    def _finalize_and_analyze_thread(self):
        """(ì‘ì—… ìŠ¤ë ˆë“œ) í‚¤ì›Œë“œ ì¶”ì¶œ(AI) ë° íŒŒì¼ ì €ì¥ì„ ìˆ˜í–‰ (ì‹œê°„ ì†Œìš”)"""
        global cap, out, microphone
        
        # 1. (ëŠë¦° ì‘ì—…) AI í‚¤ì›Œë“œ ì¶”ì¶œ
        print("ëŒ€ë³¸ ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        try:
            self.extracted_keywords = self.analysis_manager.extract_keywords_from_script(
                self.original_script, self.AI_AVAILABLE, self.text_model 
            )
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.extracted_keywords = [] # ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
        
        # 2. (ëŠë¦° ì‘ì—…) ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥
        try:
            if self.raw_audio_frames:
                print(f"WAV íŒŒì¼ ì €ì¥ ì‹œë„... (ì´ {len(self.raw_audio_frames)}ê°œ ì²­í¬)")
                wf = wave.open("output.wav", 'wb')
                
                #  'microphone' ê°ì²´ ëŒ€ì‹  'pyaudio' ê¸°ë³¸ê°’ ì‚¬ìš©
                wf.setnchannels(1) #  1ì±„ë„(ëª¨ë…¸)ë¡œ ê³ ì •
                wf.setsampwidth(microphone.SAMPLE_WIDTH)
                wf.setframerate(microphone.SAMPLE_RATE)
                
                wf.writeframes(b''.join(self.raw_audio_frames))
                wf.close()
                print("output.wav ì €ì¥ ì™„ë£Œ.")
            else:
                print("ì €ì¥í•  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"output.wav ì €ì¥ ì‹¤íŒ¨: {e}")
     
        # 3. (ëŠë¦° ì‘ì—…) ë¹„ë””ì˜¤ íŒŒì¼ ë° ì¹´ë©”ë¼ ë¦´ë¦¬ì¦ˆ 
        time.sleep(1.0) # ë¹„ë””ì˜¤ ì“°ê¸° ì™„ë£Œ ëŒ€ê¸°
        if out: 
            out.release()
            out = None
            print("ë¹„ë””ì˜¤ ë¼ì´í„° ë¦´ë¦¬ì¦ˆ ì™„ë£Œ.")
        if cap: 
            cap.release()
            cap = None
            print("ì¹´ë©”ë¼ ìº¡ì²˜ ë¦´ë¦¬ì¦ˆ ì™„ë£Œ.")
            
        # 4. (ì‘ì—… ìŠ¤ë ˆë“œ) ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„, ë©”ì¸ ìŠ¤ë ˆë“œì— ê²°ê³¼ í˜ì´ì§€ í‘œì‹œ ìš”ì²­
        if self.winfo_exists(): 
            self.after(0, self.show_analysis_page)
    # =========================================================================

    def show_analysis_page(self):
        self.clear_window()
        main_canvas = tk.Canvas(self)
        scrollbar = ttk.Scrollbar(self, orient="vertical", command=main_canvas.yview)
        scrollable_frame = ttk.Frame(main_canvas)
        scrollable_frame.bind("<Configure>", lambda e: main_canvas.configure(scrollregion=main_canvas.bbox("all")))
        canvas_frame = main_canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        main_canvas.bind("<Configure>", lambda e: main_canvas.itemconfig(canvas_frame, width=e.width))
        main_canvas.configure(yscrollcommand=scrollbar.set)
        main_canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        self.bind_all("<MouseWheel>", lambda e: main_canvas.yview_scroll(int(-1*(e.delta/120)), "units"))
        content = ttk.Frame(scrollable_frame, padding=30)
        content.pack(fill='both', expand=True)
        
        duration_min = max(0.1, (time.time() - start_time) / 60)
        
        wpm = int(speech_data['word_count'] / duration_min) if speech_data['word_count'] > 0 else 0 
        score_speed = max(0, 100 - abs(130 - wpm))
        total_frames = max(1, gaze_data['total_frames'])
        gaze_ratio = int((gaze_data['looking_frames'] / total_frames) * 100)
        score_gaze = min(100, int(gaze_ratio * 1.43))
        mode = self.user_settings.get('atmosphere', 'ì •ë³´')
        
        if len(speech_data['full_transcript'].strip()) > 10:
            match_rate, match_label_text = self.analysis_manager.calculate_smart_match(
                self.original_script, speech_data['full_transcript'], mode
            )
        else:
            match_rate, match_label_text = 0, "ë°ì´í„° ë¶€ì¡±"
            
        score_match = match_rate
        filler_deduction = speech_data['filler_count'] * 3
        tremble_score = max(0, 100 - int(audio_data['tremble_count'] / duration_min * 2))
        score_fluency = int((max(0, 100 - filler_deduction) + tremble_score) / 2)
        
        if 'ì •ë³´' in mode: total_score = int(score_match * 0.4 + score_fluency * 0.3 + score_gaze * 0.2 + score_speed * 0.1)
        elif 'ì„¤ë“' in mode: total_score = int(score_gaze * 0.4 + score_speed * 0.2 + score_fluency * 0.2 + score_match * 0.2)
        else: total_score = int(score_match * 0.3 + score_gaze * 0.3 + score_fluency * 0.2 + score_speed * 0.2)
        self.save_history(total_score)
        
        tk.Label(content, text=f"ğŸ† ì¢…í•© ì ìˆ˜: {total_score}ì ", font=("Arial", 36, "bold"), fg="#007aff").pack(pady=20)
        summary = ttk.Frame(content); summary.pack(pady=10, fill='x')
        for i in range(4): summary.columnconfigure(i, weight=1)
        self.create_stat_card(summary, 0, "ğŸ—£ï¸ ì†ë„", f"{wpm} WPM", score_speed)
        self.create_stat_card(summary, 1, f"ğŸ“ {match_label_text}", f"{match_rate}%", score_match)
        self.create_stat_card(summary, 2, "ğŸ‘€ ì‹œì„  ì²˜ë¦¬", f"{gaze_ratio}%", score_gaze)
        self.create_stat_card(summary, 3, "ğŸŒŠ ìœ ì°½ì„±", f"{score_fluency}ì ", score_fluency)
        
        self.create_video_player(content)
        self.create_score_graph(content)
        self.create_feedback_section(content, mode, match_rate, gaze_ratio, score_fluency, wpm, speech_data['full_transcript'], audio_data['volumes'])
        
        ttk.Button(content, text="ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°", command=self.show_setup_page).pack(pady=30)
        self.load_video()

    def create_stat_card(self, parent, col, title, value, score):
        frame = tk.Frame(parent, bg="white", bd=1, relief="solid")
        frame.grid(row=0, column=col, padx=10, sticky="nsew")
        tk.Label(frame, text=title, font=("Arial", 12, "bold"), bg="white").pack(pady=(10,5))
        tk.Label(frame, text=value, font=("Arial", 18), fg="#007aff", bg="white").pack()
        tk.Label(frame, text=f"(ì ìˆ˜: {score})", font=("Arial", 10), fg="gray", bg="white").pack(pady=(0,10))

    def create_video_player(self, parent):
        player_frame = ttk.LabelFrame(parent, text=" ğŸ¦ ë…¹í™” ì˜ìƒ ë¦¬ë·° (íƒ€ì„ë¼ì¸ í´ë¦­) ")
        player_frame.pack(fill='both', expand=True, padx=20, pady=20)
        self.vid_player_label = ttk.Label(player_frame); self.vid_player_label.pack(pady=10, fill='both', expand=True)
        self.timeline = tk.Canvas(player_frame, height=40, bg="#e9ecef"); self.timeline.pack(fill='x', padx=10)
        self.timeline.bind("<Button-1>", self.on_timeline_click)
        self.vid_slider = ttk.Scale(player_frame, from_=0, to=100, orient="horizontal", command=self.on_slider_move)
        self.vid_slider.pack(fill='x', padx=10, pady=(0, 10))
        btn_frame = ttk.Frame(player_frame); btn_frame.pack(pady=10)
        ttk.Button(btn_frame, text="â–¶ ì¬ìƒ (ì†Œë¦¬ ON)", command=self.play_video_with_sound).pack(side='left', padx=5)
        ttk.Button(btn_frame, text="â–  ì •ì§€", command=self.stop_video).pack(side='left', padx=5)

    def create_score_graph(self, parent):
        """[ìˆ˜ì •ë¨] Xì¶• ëˆˆê¸ˆ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ ê·¸ë˜í”„ ìƒì„±"""
        graph_frame = ttk.Frame(parent); graph_frame.pack(fill='x', pady=20, padx=20)
        fig, ax = plt.subplots(figsize=(8, 2.5))
        
        history_len = len(self.history)
        
        if history_len > 0:
            x_ticks = range(1, history_len + 1)
            ax.plot(x_ticks, self.history, marker='o', linestyle='-', color='#007aff', linewidth=2)
            ax.fill_between(x_ticks, self.history, color='#007aff', alpha=0.1)
            ax.set_title("ì—°ìŠµ ì ìˆ˜ íŠ¸ë Œë“œ")
            ax.set_ylim(0, 105)
            
            ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))
            ax.set_xlim(0.5, history_len + 0.5)
            
            if history_len == 1:
                ax.set_xticks([1])
            elif history_len < 10:
                 ax.set_xticks(x_ticks)

            ax.grid(True, linestyle='--')
            
        canvas = FigureCanvasTkAgg(fig, master=graph_frame); canvas.draw(); canvas.get_tk_widget().pack(fill='both')


    def create_feedback_section(self, parent, mode_raw, match_rate, gaze_ratio, fluency, wpm, transcript, volume_data):
        fb_frame = tk.LabelFrame(parent, text="ğŸ¤– AI ì½”ì¹˜ í”¼ë“œë°±", font=("Arial", 14, "bold"))
        fb_frame.pack(fill='x', pady=20, ipady=10)
        
        if 'ì •ë³´' in mode_raw: mapped_mode = 'ë…¼ë¦¬ì '; target_type_key = 'A'
        elif 'ê³µê°' in mode_raw: mapped_mode = 'ì¹œí™”ì '; target_type_key = 'C'
        else: mapped_mode = 'ì—´ì •ì '; target_type_key = 'B'
        
        final_report_text = ""

        if wpm == 0 and len(transcript.strip()) < 10:
            final_report_text = "ğŸš¨ **ë°ì´í„° ë¶€ì¡± ê²½ê³ :**\nìŒì„± ë°ì´í„°ê°€ ì¶©ë¶„íˆ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\në§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•˜ê³ , ë…¹í™” ì¤‘ ë” í¬ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
        else:
            final_report_text += "--- ğŸ“ˆ AI ì½”ì¹­ ë¦¬í¬íŠ¸ (ê·œì¹™ ê¸°ë°˜) ---\n"
            
            style_feedback = self.analysis_manager.analyze_speech_style(transcript, mapped_mode)
            energy_feedback = self.analysis_manager.analyze_vocal_energy(volume_data, mapped_mode)
            delivery_metrics = {"wpm": wpm}
            
            final_report_text += f"{style_feedback}\n"
            final_report_text += f"{energy_feedback}\n\n"
            
            imrad_report = []
            if target_type_key == 'A':
                imrad_report = self.imrad_validator.validate_imrad_sections(self.original_script)
            
            if imrad_report: 
                final_report_text += "--- [ë…¼ë¦¬ êµ¬ì¡° ê²½ê³ ] ---\n" + "\n".join(imrad_report) + "\n\n"
            
            final_report_text += "--- ğŸ¤– AI ì‹¬ì¸µ í”¼ë“œë°± (Gemini) ---\n"

            ai_generated_feedback = None 
            
            if self.AI_AVAILABLE and self.text_model: 
                print("AI ì‹¬ì¸µ ì½”ì¹­ ë¦¬í¬íŠ¸ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤... (gemini-2.5-pro)")
                try:
                    ai_generated_feedback = self.analysis_manager.generate_ai_feedback(
                        self.text_model, transcript, target_type_key, delivery_metrics, 
                        style_feedback, energy_feedback, imrad_report
                    )
                except Exception as e:
                    print(f"AI ì‹¬ì¸µ í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
                    ai_generated_feedback = f"AI ì‹¬ì¸µ í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            
            if ai_generated_feedback:
                final_report_text += ai_generated_feedback
            else:
                print("AI ì½”ì¹­ APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                
                fallback_text = "Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì‹¬ì¸µ í”¼ë“œë°±ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëŒ€ì‹  ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n"
                
                if fluency < 70: fallback_text += "âš ï¸ [ìœ ì°½ì„±] ëª©ì†Œë¦¬ ë–¨ë¦¼ì´ë‚˜ 'ìŒ, ì–´' ê°™ì€ í•„ëŸ¬ì›Œë“œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                if wpm > 150: fallback_text += f"âš ï¸ [ì†ë„] ë§ì´ ë‹¤ì†Œ ë¹ ë¦…ë‹ˆë‹¤ ({wpm} WPM).\n"
                elif wpm < 100 and wpm > 0: fallback_text += f"âš ï¸ [ì†ë„] ë§ì´ ë‹¤ì†Œ ëŠë¦½ë‹ˆë‹¤ ({wpm} WPM).\n"
                
                if len(fallback_text.split('\n')) < 6:
                    fallback_text += "\nğŸ‰ ì „ë°˜ì ìœ¼ë¡œ ì•„ì£¼ í›Œë¥­í•œ ë°œí‘œ ì—­ëŸ‰ì„ ë³´ì—¬ì£¼ì…¨ìŠµë‹ˆë‹¤!"
                
                final_report_text += fallback_text
        
        tk.Label(fb_frame, text=final_report_text, font=("Arial", 12), justify="left", wraplength=800, padx=20).pack(anchor='w', fill='x')

    def load_video(self):
        try:
            # ë¹„ë””ì˜¤ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not os.path.exists('output.avi'):
                print("ë…¹í™” íŒŒì¼(output.avi)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”Œë ˆì´ì–´ë¥¼ ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                self.vid_player_label.config(text="ë…¹í™”ëœ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n(output.avi)", foreground="red")
                return
                
            self.vid_cap = cv2.VideoCapture('output.avi')
            if not self.vid_cap.isOpened():
                print("ë…¹í™” íŒŒì¼(output.avi)ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.vid_player_label.config(text="ë…¹í™” íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", foreground="red")
                return
                
            self.vid_duration = max(1, self.vid_cap.get(cv2.CAP_PROP_FRAME_COUNT) / self.vid_cap.get(cv2.CAP_PROP_FPS))
            self.is_playing = False
            self.draw_timeline()
            self.vid_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            self.update_frame()
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
            if hasattr(self, 'vid_player_label'):
                self.vid_player_label.config(text=f"ë¹„ë””ì˜¤ ë¡œë“œ ì˜¤ë¥˜: {e}", foreground="red")

    def draw_timeline(self):
        if not hasattr(self, 'timeline') or not self.timeline.winfo_exists(): return
        self.timeline.delete("all")
        self.update_idletasks()
        try:
            w = self.timeline.winfo_width()
            if w < 2: w = 1100 # ë„ˆë¹„ê°€ 0ì¼ ê²½ìš° ê¸°ë³¸ê°’
            self.timeline.create_line(0, 20, w, 20, fill="#ced4da", width=2)
            for m in timeline_markers:
                if self.vid_duration > 0:
                    x = (m['time'] / self.vid_duration) * w
                    self.timeline.create_text(x, 20, text=m['label'], font=("Arial", 16), tags=(str(m['time']),))
        except Exception as e:
            print(f"íƒ€ì„ë¼ì¸ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}") 

    def on_timeline_click(self, event):
        if not hasattr(self, 'timeline') or not self.timeline.winfo_exists(): return
        tags = self.timeline.gettags(self.timeline.find_closest(event.x, event.y))
        if tags: self.seek(float(tags[0]))

    def on_slider_move(self, val): 
        if hasattr(self, 'vid_duration'):
            self.seek((float(val) / 100) * self.vid_duration)
            
    def seek(self, sec):
        if hasattr(self, 'vid_cap') and self.vid_cap and self.vid_cap.isOpened():
            self.vid_cap.set(cv2.CAP_PROP_POS_FRAMES, int(sec * self.vid_cap.get(cv2.CAP_PROP_FPS)))
            self.update_frame()

    # =========================================================================
    # =========================================================================
    
    def audio_playback_thread(self):
        """ì˜¤ë””ì˜¤ ì¬ìƒì„ ìœ„í•œ ë³„ë„ ìŠ¤ë ˆë“œ (pyaudio ì‚¬ìš©)"""
        global pa
        CHUNK = 1024
        
        try:
            if not os.path.exists("output.wav"):
                print("output.wav íŒŒì¼ì´ ì—†ì–´ ì†Œë¦¬ ì—†ì´ ì¬ìƒí•©ë‹ˆë‹¤.")
                return
            
            wf = wave.open("output.wav", 'rb')
            
            # ì „ì—­ 'pa' ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
            stream = pa.open(format=pa.get_format_from_width(wf.getsampwidth()),
                             channels=wf.getnchannels(),
                             rate=wf.getframerate(),
                             output=True)

            data = wf.readframes(CHUNK)

            # self.is_playing í”Œë˜ê·¸ë¥¼ í™•ì¸í•˜ë©° ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
            while data and self.is_playing:
                stream.write(data)
                data = wf.readframes(CHUNK)

            stream.stop_stream()
            stream.close()
            wf.close()
            
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ì¬ìƒ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
        
        # ì˜¤ë””ì˜¤ê°€ ëë‚˜ê±°ë‚˜ ì¤‘ì§€ë˜ë©´ is_playingì„ Falseë¡œ ì„¤ì •
        self.is_playing = False

    def play_video_with_sound(self):
        """[ìˆ˜ì •] ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ìŠ¤ë ˆë“œë¥¼ 'ë™ì‹œì—' ì‹œì‘ (winsound ì œê±°)"""
        if self.is_playing: return
        if not hasattr(self, 'vid_cap') or not self.vid_cap or not self.vid_cap.isOpened():
            messagebox.showwarning("ì¬ìƒ ì˜¤ë¥˜", "ì¬ìƒí•  ë¹„ë””ì˜¤ íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
            
        self.is_playing = True
        
        threading.Thread(target=self.audio_playback_thread, daemon=True).start()
        
        self.play_video_loop()

    def stop_video(self):
        """[ìˆ˜ì •] is_playing í”Œë˜ê·¸ë§Œ ì„¤ì • (winsound ì œê±°)"""
        self.is_playing = False

    def play_video_loop(self):
        if not self.winfo_exists(): 
            self.is_playing = False # ì°½ì´ ë‹«íˆë©´ ì¬ìƒ ì¤‘ì§€
            return
        if not hasattr(self, 'vid_cap') or not self.vid_cap or not self.vid_cap.isOpened():
            self.is_playing = False
            return
            
        if self.is_playing:
            ret, frame = self.vid_cap.read()
            if ret:
                self.show_frame(frame)
                current_pos = self.vid_cap.get(cv2.CAP_PROP_POS_MSEC) / 1000
                
                if hasattr(self, 'vid_slider'):
                    self.vid_slider.set((current_pos / self.vid_duration) * 100)
                self.after(33, self.play_video_loop) # ì•½ 30fps
            else: 
                self.stop_video()
                if hasattr(self, 'vid_cap') and self.vid_cap:
                    self.vid_cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # ì¬ìƒ ì™„ë£Œ ì‹œ ì²˜ìŒìœ¼ë¡œ ë˜ê°ê¸°


    def update_frame(self):
        if hasattr(self, 'vid_cap') and self.vid_cap and self.vid_cap.isOpened():
            ret, frame = self.vid_cap.read()
            if ret: self.show_frame(frame)

    def show_frame(self, frame):
        try:
            if not hasattr(self, 'vid_player_label') or not self.vid_player_label.winfo_exists():
                return
                
            w = self.vid_player_label.winfo_width()
            if w > 1:
                target_h = int(w * (9 / 16)) # 16:9 ë¹„ìœ¨ë¡œ ë†’ì´ ê³„ì‚°
                
                # ì›ë³¸ í”„ë ˆì„ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
                h, w_orig = frame.shape[:2]
                scale = target_h / h
                target_w = int(w_orig * scale)
                
                # ë¦¬ì‚¬ì´ì¦ˆ (ê°€ë¡œ/ì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€)
                resized_frame = cv2.resize(frame, (target_w, target_h), interpolation=cv2.INTER_AREA)

                img = ImageTk.PhotoImage(Image.fromarray(cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)))
                self.vid_player_label.configure(image=img, anchor='center'); self.vid_player_label.image = img
            else:
                img = ImageTk.PhotoImage(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((640, 360)))
                self.vid_player_label.configure(image=img, anchor='center'); self.vid_player_label.image = img
        except Exception as e:
            # print(f"í”„ë ˆì„ í‘œì‹œ ì˜¤ë¥˜: {e}") # ë””ë²„ê¹… ì‹œ ì£¼ì„ í•´ì œ
            pass 

    def show_rewriter_window(self):
        if not self.AI_AVAILABLE:
            messagebox.showerror("ê¸°ëŠ¥ ë¹„í™œì„±í™”", "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ëŒ€ë³¸ ì¬ì‘ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        self.rewriter_win = tk.Toplevel(self)
        self.rewriter_win.title("ğŸ“¢ AI ëŒ€ë³¸ ì¬ì‘ì„± (Gemini)")
        self.rewriter_win.geometry("1000x700")

        main_frame = ttk.Frame(self.rewriter_win, padding=10)
        main_frame.pack(fill='both', expand=True)
        
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill='x', pady=5)
        
        ttk.Label(control_frame, text="ë³€í™˜í•  ìŠ¤íƒ€ì¼:").pack(side='left', padx=(0, 5))
        self.rewrite_mode = tk.StringVar(value='B')
        modes = [('ì •ë³´í˜• (A)', 'A'), ('ì„¤ë“í˜• (B)', 'B'), ('ê³µê°í˜• (C)', 'C')]
        for text, mode in modes:
            ttk.Radiobutton(control_frame, text=text, variable=self.rewrite_mode, value=mode).pack(side='left', padx=5)
        

        text_frame = ttk.Frame(main_frame)
        text_frame.pack(fill='both', expand=True, pady=5)
        text_frame.columnconfigure(0, weight=1); text_frame.columnconfigure(1, weight=1)
        text_frame.rowconfigure(0, weight=1)

        left_pane = ttk.Frame(text_frame, padding=5)
        left_pane.grid(row=0, column=0, sticky='nsew')
        ttk.Label(left_pane, text="[ì›ë³¸ ëŒ€ë³¸]ì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:").pack(anchor='w')
        self.original_text = tk.Text(left_pane, height=30, width=50, font=("Arial", 11), wrap='word')
        self.original_text.pack(fill='both', expand=True)

        right_pane = ttk.Frame(text_frame, padding=5)
        right_pane.grid(row=0, column=1, sticky='nsew')
        ttk.Label(right_pane, text="[AI ë³€í™˜ ê²°ê³¼]:").pack(anchor='w')
        self.rewritten_text = tk.Text(right_pane, height=30, width=50, font=("Arial", 11), wrap='word', state='disabled')
        self.rewritten_text.pack(fill='both', expand=True)

        action_frame = ttk.Frame(main_frame)
        action_frame.pack(fill='x', pady=10)
        
        self.rewrite_status_label = ttk.Label(action_frame, text="ì¤€ë¹„ ì™„ë£Œ.", foreground="gray")
        self.rewrite_status_label.pack(side='left', padx=10)
          
        self.rewrite_btn = ttk.Button(action_frame, text="ğŸš€ ëŒ€ë³¸ ë³€í™˜ ì‹¤í–‰", command=self.run_rewriter)
        self.rewrite_btn.pack(side='right')

    def run_rewriter(self):
        script = self.original_text.get("1.0", tk.END).strip()
        if len(script) < 20:
            messagebox.showwarning("ì˜¤ë¥˜", "ì›ë³¸ ëŒ€ë³¸ì„ 20ì ì´ìƒ ì…ë ¥í•˜ì„¸ìš”.", parent=self.rewriter_win)
            return
            
        if not hasattr(self, 'ai_announcer') or not hasattr(self.ai_announcer, 'rewrite'):
            messagebox.showerror("ì˜¤ë¥˜", "AI Rewriterê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", parent=self.rewriter_win)
            return

        mode = self.rewrite_mode.get()
        
        self.rewrite_status_label.config(text="AIê°€ ëŒ€ë³¸ì„ ì¬ì‘ì„± ì¤‘ì…ë‹ˆë‹¤... (ìµœëŒ€ 30ì´ˆ ì†Œìš”)", foreground="blue")
        self.rewrite_btn.config(state='disabled')
        self.rewriter_win.update()

        threading.Thread(target=self._rewrite_thread_target, args=(script, mode), daemon=True).start()

    def _rewrite_thread_target(self, script, mode):
        """[ìŠ¤ë ˆë“œ] ëŒ€ë³¸ ì¬ì‘ì„± (API í˜¸ì¶œ)"""
        try:
            rewritten_script = self.ai_announcer.rewrite(script, mode)
            if self.winfo_exists():
                self.after(0, self.update_rewriter_ui, rewritten_script)
        except Exception as e:
            print(f"ëŒ€ë³¸ ì¬ì‘ì„± ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            if self.winfo_exists():
                self.after(0, self.update_rewriter_ui, f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                
    def update_rewriter_ui(self, rewritten_script):
        if hasattr(self, 'rewriter_win') and self.rewriter_win.winfo_exists():
            self.rewritten_text.config(state='normal')
            self.rewritten_text.delete("1.0", tk.END)
            self.rewritten_text.insert("1.0", rewritten_script)
            self.rewritten_text.config(state='disabled')
            
            if "ì˜¤ë¥˜" in rewritten_script or "âŒ" in rewritten_script:
                self.rewrite_status_label.config(text="ëŒ€ë³¸ ì¬ì‘ì„± ì‹¤íŒ¨.", foreground="red")
                self.rewrite_btn.config(state='normal')
            else:
                self.rewrite_status_label.config(text="ë³€í™˜ ì™„ë£Œ!", foreground="green")
                self.rewrite_btn.config(state='normal')

if __name__ == "__main__":
    app = App()
    app.mainloop()
